{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# The Last Frequency: SOTA K-Fold Ensemble Solution\n",
                "\n",
                "Targeting 0.95+ with a 5-Fold Ensemble of ResNet-18 models trained from scratch.\n",
                "\n",
                "### Why K-Fold?\n",
                "In audio tasks, specific samples can be tricky. A single model might miss patterns that another fold catches. By training **5 models** on different data subsets and averaging their confidence (probabilities), we significantly reduce variance and improve generalization on the private leaderboard."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import json\n",
                "import random\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from tqdm.auto import tqdm\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torchaudio\n",
                "import torchvision.models as models\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "def seed_everything(seed=42):\n",
                "    random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "    torch.backends.cudnn.benchmark = False\n",
                "\n",
                "seed_everything(42)\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CFG:\n",
                "    data_dir = '/kaggle/input/the-last-frequency'\n",
                "    sample_rate = 16000\n",
                "    n_fft = 1024\n",
                "    hop_length = 256\n",
                "    n_mels = 128\n",
                "    target_frames = 64\n",
                "    \n",
                "    # K-Fold specific\n",
                "    n_splits = 5\n",
                "    batch_size = 64\n",
                "    epochs = 35 # 35 epochs per fold is usually enough for scratch ResNet\n",
                "    lr = 1e-3\n",
                "    weight_decay = 1e-2\n",
                "    label_smoothing = 0.1\n",
                "    mixup_alpha = 0.2\n",
                "    \n",
                "    num_classes = 35"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Loading data...\")\n",
                "train_waveforms = np.load(f'{CFG.data_dir}/train_waveforms.npy')\n",
                "train_labels = np.load(f'{CFG.data_dir}/train_labels.npy')\n",
                "\n",
                "with open(f'{CFG.data_dir}/label_map.json') as f:\n",
                "    label_map = {int(k): v for k, v in json.load(f).items()}\n",
                "\n",
                "print(f'Train shape: {train_waveforms.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Augments & Model Logic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class AudioAugmentor:\n",
                "    @staticmethod\n",
                "    def time_shift(waveform, shift_limit=0.1):\n",
                "        shift = int(random.uniform(-shift_limit, shift_limit) * waveform.shape[0])\n",
                "        return np.roll(waveform, shift)\n",
                "\n",
                "class SpecTransform(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.mel_spec = torchaudio.transforms.MelSpectrogram(\n",
                "            sample_rate=CFG.sample_rate, n_fft=CFG.n_fft, \n",
                "            hop_length=CFG.hop_length, n_mels=CFG.n_mels\n",
                "        )\n",
                "        self.amplitude_to_db = torchaudio.transforms.AmplitudeToDB()\n",
                "        self.freq_mask = torchaudio.transforms.FrequencyMasking(20)\n",
                "        self.time_mask = torchaudio.transforms.TimeMasking(15)\n",
                "\n",
                "    def forward(self, x, augment=False):\n",
                "        spec = self.mel_spec(x)\n",
                "        spec = self.amplitude_to_db(spec)\n",
                "        if spec.shape[-1] > CFG.target_frames:\n",
                "            spec = spec[..., :CFG.target_frames]\n",
                "        elif spec.shape[-1] < CFG.target_frames:\n",
                "            spec = F.pad(spec, (0, CFG.target_frames - spec.shape[-1]))\n",
                "        if augment:\n",
                "            spec = self.freq_mask(spec)\n",
                "            spec = self.time_mask(spec)\n",
                "        return spec\n",
                "\n",
                "class AudioResNet(nn.Module):\n",
                "    def __init__(self, num_classes=35):\n",
                "        super().__init__()\n",
                "        model = models.resnet18(weights=None)\n",
                "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
                "        model.fc = nn.Sequential(nn.Dropout(0.3), nn.Linear(model.fc.in_features, num_classes))\n",
                "        self.backbone = model\n",
                "        self.spec_layer = SpecTransform()\n",
                "\n",
                "    def forward(self, x, augment=False):\n",
                "        x = self.spec_layer(x, augment=augment)\n",
                "        x = x.unsqueeze(1)\n",
                "        return self.backbone(x)\n",
                "\n",
                "class SpeechDataset(Dataset):\n",
                "    def __init__(self, waveforms, labels=None, augment=False):\n",
                "        self.waveforms = waveforms\n",
                "        self.labels = labels\n",
                "        self.augment = augment\n",
                "        self.augmentor = AudioAugmentor()\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.waveforms)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        waveform = self.waveforms[idx].copy()\n",
                "        if self.augment:\n",
                "            waveform = self.augmentor.time_shift(waveform)\n",
                "        waveform = torch.from_numpy(waveform).float()\n",
                "        if self.labels is not None: return waveform, self.labels[idx]\n",
                "        return waveform\n",
                "\n",
                "def mixup_data(x, y, alpha=0.2):\n",
                "    lam = np.random.beta(alpha, alpha) if alpha > 0 else 1\n",
                "    index = torch.randperm(x.size()[0]).to(device)\n",
                "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
                "    return mixed_x, y, y[index], lam"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### K-Fold Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=42)\n",
                "oof_preds = np.zeros(len(train_labels))\n",
                "\n",
                "for fold, (train_idx, val_idx) in enumerate(skf.split(train_waveforms, train_labels)):\n",
                "    print(f\"\\n{'='*20} Fold {fold+1}/{CFG.n_splits} {'='*20}\")\n",
                "    \n",
                "    train_ds = SpeechDataset(train_waveforms[train_idx], train_labels[train_idx], augment=True)\n",
                "    val_ds = SpeechDataset(train_waveforms[val_idx], train_labels[val_idx], augment=False)\n",
                "    \n",
                "    train_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, num_workers=2)\n",
                "    val_loader = DataLoader(val_ds, batch_size=CFG.batch_size, shuffle=False)\n",
                "    \n",
                "    model = AudioResNet(CFG.num_classes).to(device)\n",
                "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
                "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
                "        optimizer, max_lr=CFG.lr*2, steps_per_epoch=len(train_loader), epochs=CFG.epochs\n",
                "    )\n",
                "    criterion = nn.CrossEntropyLoss(label_smoothing=CFG.label_smoothing)\n",
                "    \n",
                "    best_fold_acc = 0\n",
                "    \n",
                "    for epoch in range(1, CFG.epochs + 1):\n",
                "        model.train()\n",
                "        for x, y in train_loader:\n",
                "            x, y = x.to(device), y.to(device)\n",
                "            if random.random() < 0.5:\n",
                "                x, y_a, y_b, lam = mixup_data(x, y, CFG.mixup_alpha)\n",
                "                preds = model(x, augment=True)\n",
                "                loss = lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)\n",
                "            else:\n",
                "                preds = model(x, augment=True)\n",
                "                loss = criterion(preds, y)\n",
                "            \n",
                "            optimizer.zero_grad(); loss.backward(); optimizer.step(); scheduler.step()\n",
                "            \n",
                "        # Validate\n",
                "        model.eval()\n",
                "        fold_preds = []\n",
                "        fold_targets = []\n",
                "        with torch.no_grad():\n",
                "            for x, y in val_loader:\n",
                "                out = model(x.to(device))\n",
                "                fold_preds.extend(out.argmax(1).cpu().numpy())\n",
                "                fold_targets.extend(y.numpy())\n",
                "        \n",
                "        acc = accuracy_score(fold_targets, fold_preds)\n",
                "        if acc > best_fold_acc:\n",
                "            best_fold_acc = acc\n",
                "            torch.save(model.state_dict(), f'best_model_fold_{fold}.pth')\n",
                "            \n",
                "        if epoch % 10 == 0 or epoch == CFG.epochs:\n",
                "            print(f\"Epoch {epoch} | Val Acc: {acc:.4f} | Best: {best_fold_acc:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Multi-Fold Inference (Ensemble)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_fold_probs(waveforms):\n",
                "    all_probs = []\n",
                "    ds = SpeechDataset(waveforms, augment=False)\n",
                "    loader = DataLoader(ds, batch_size=CFG.batch_size, shuffle=False)\n",
                "    \n",
                "    for fold in range(CFG.n_splits):\n",
                "        print(f\"Predicting with Fold {fold+1}...\")\n",
                "        model = AudioResNet(CFG.num_classes).to(device)\n",
                "        model.load_state_dict(torch.load(f'best_model_fold_{fold}.pth'))\n",
                "        model.eval()\n",
                "        \n",
                "        fold_prob = []\n",
                "        with torch.no_grad():\n",
                "            for x in tqdm(loader):\n",
                "                out = model(x.to(device))\n",
                "                probs = F.softmax(out, dim=1)\n",
                "                fold_prob.append(probs.cpu().numpy())\n",
                "        all_probs.append(np.concatenate(fold_prob))\n",
                "        \n",
                "    return np.mean(all_probs, axis=0)\n",
                "\n",
                "print(\"Loading test sets...\")\n",
                "public_test = np.load(f'{CFG.data_dir}/public_test_waveforms.npy')\n",
                "private_test = np.load(f'{CFG.data_dir}/private_test_waveforms.npy')\n",
                "\n",
                "print(\"Ensembling 5 models for Public and Private test sets...\")\n",
                "public_probs = get_fold_probs(public_test)\n",
                "private_probs = get_fold_probs(private_test)\n",
                "\n",
                "final_indices = np.concatenate([\n",
                "    public_probs.argmax(1), \n",
                "    private_probs.argmax(1)\n",
                "])\n",
                "\n",
                "all_commands = [label_map[idx] for idx in final_indices]\n",
                "submission = pd.DataFrame({'Id': range(len(all_commands)), 'Command': all_commands})\n",
                "submission.to_csv('submission.csv', index=False)\n",
                "print(\"Submission with K-Fold Ensemble saved!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}