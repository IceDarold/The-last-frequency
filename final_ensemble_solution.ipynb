{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# The Last Frequency: Final Winning Ensemble (STRICT COMPATIBILITY)\n",
                "\n",
                "Этот блокнот объединяет ResNet-18, ResNet-34 и EfficientNet-B0. \n",
                "Архитектура строго подогнана под SOTA-модели с Delta-признаками и Sequential-слоями."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, json, numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F, torchaudio, torchvision.models as models\n",
                "from tqdm.auto import tqdm\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "MODEL_PATH = '/kaggle/input/the-last-frequency-models'\n",
                "DATA_DIR = '/kaggle/input/the-last-frequency'\n",
                "\n",
                "class CFG:\n",
                "    sample_rate, n_fft, hop_length, n_mels, target_frames = 16000, 1024, 256, 128, 64\n",
                "    batch_size = 128\n",
                "    num_classes = 35\n",
                "\n",
                "with open(f'{DATA_DIR}/label_map.json') as f: \n",
                "    label_map = {int(k): v for k, v in json.load(f).items()}\n",
                "\n",
                "class SpecTransform(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.mel_spec = torchaudio.transforms.MelSpectrogram(sample_rate=CFG.sample_rate, n_fft=CFG.n_fft, hop_length=CFG.hop_length, n_mels=CFG.n_mels)\n",
                "        self.amp_to_db = torchaudio.transforms.AmplitudeToDB()\n",
                "    def forward(self, x):\n",
                "        spec = self.amp_to_db(self.mel_spec(x))\n",
                "        if spec.shape[-1] > CFG.target_frames: spec = spec[..., :CFG.target_frames]\n",
                "        elif spec.shape[-1] < CFG.target_frames: spec = F.pad(spec, (0, CFG.target_frames - spec.shape[-1]))\n",
                "        \n",
                "        # ВАЖНО: Модели обучались на 3-х каналах (Spec + Delta + Delta-Delta)\n",
                "        delta = torchaudio.functional.compute_deltas(spec)\n",
                "        delta2 = torchaudio.functional.compute_deltas(delta)\n",
                "        return torch.stack([spec, delta, delta2], dim=1)\n",
                "\n",
                "class AudioResNet(nn.Module):\n",
                "    def __init__(self, arch='resnet18'):\n",
                "        super().__init__()\n",
                "        if arch == 'resnet18': model = models.resnet18(weights=None)\n",
                "        else: model = models.resnet34(weights=None)\n",
                "        \n",
                "        # ВАЖНО: Возвращаем Conv2d к 3 каналам (по умолчанию в ResNet) для Delta-фичей\n",
                "        # ВАЖНО: Архитектура fc должна быть Sequential, чтобы ключиfc.1.weight совпали\n",
                "        model.fc = nn.Sequential(\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(model.fc.in_features, CFG.num_classes)\n",
                "        )\n",
                "        self.backbone, self.spec_layer = model, SpecTransform()\n",
                "    def forward(self, x): return self.backbone(self.spec_layer(x))\n",
                "\n",
                "class AudioEffNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        model = models.efficientnet_b0(weights=None)\n",
                "        # Переключаем на 3 канала\n",
                "        old_conv = model.features[0][0]\n",
                "        model.features[0][0] = nn.Conv2d(3, old_conv.out_channels, 3, stride=2, padding=1, bias=False)\n",
                "        \n",
                "        model.classifier[1] = nn.Sequential(\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(model.classifier[1].in_features, CFG.num_classes)\n",
                "        )\n",
                "        self.backbone, self.spec_layer = model, SpecTransform()\n",
                "    def forward(self, x): return self.backbone(self.spec_layer(x))\n",
                "\n",
                "class TestDataset(Dataset):\n",
                "    def __init__(self, waveforms): self.waveforms = waveforms\n",
                "    def __len__(self): return len(self.waveforms)\n",
                "    def __getitem__(self, idx): return torch.from_numpy(self.waveforms[idx]).float()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_probs(waveforms):\n",
                "    loader = DataLoader(TestDataset(waveforms), batch_size=CFG.batch_size, shuffle=False)\n",
                "    all_probs = []\n",
                "    \n",
                "    # Список моделей с весами для блендинга\n",
                "    models_to_run = [\n",
                "        (lambda: AudioResNet(arch='resnet18'), 1.0, 'best_model_fold'), \n",
                "        (lambda: AudioResNet(arch='resnet34'), 1.2, 'resnet34_fold'), \n",
                "        (AudioEffNet, 1.1, 'effnet_fold')\n",
                "    ]\n",
                "    \n",
                "    for model_factory, weight, prefix in models_to_run:\n",
                "        for fold in range(5):\n",
                "            path = f'{MODEL_PATH}/{prefix}_{fold}.pth'\n",
                "            if not os.path.exists(path):\n",
                "                print(f\"Warning: {path} not found.\")\n",
                "                continue\n",
                "            \n",
                "            print(f\"Predicting with {prefix}_{fold}...\")\n",
                "            model = model_factory().to(device)\n",
                "            model.load_state_dict(torch.load(path, map_location=device))\n",
                "            model.eval()\n",
                "            \n",
                "            probs = []\n",
                "            with torch.no_grad():\n",
                "                for x in tqdm(loader, leave=False): \n",
                "                    out = model(x.to(device))\n",
                "                    probs.append(F.softmax(out, dim=1).cpu().numpy() * weight)\n",
                "            all_probs.append(np.concatenate(probs))\n",
                "            \n",
                "    return np.sum(all_probs, axis=0)\n",
                "\n",
                "print(\"Loading test data...\")\n",
                "pub = np.load(f'{DATA_DIR}/public_test_waveforms.npy')\n",
                "priv = np.load(f'{DATA_DIR}/private_test_waveforms.npy')\n",
                "\n",
                "print(\"Starting inference...\")\n",
                "final_pub_probs = get_probs(pub)\n",
                "final_priv_probs = get_probs(priv)\n",
                "\n",
                "final_indices = np.concatenate([final_pub_probs.argmax(1), final_priv_probs.argmax(1)])\n",
                "final_cmds = [label_map[idx] for idx in final_indices]\n",
                "\n",
                "pd.DataFrame({'Id': range(len(final_cmds)), 'Command': final_cmds}).to_csv('submission.csv', index=False)\n",
                "print(\"Done! Fixed submission.csv ready.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}