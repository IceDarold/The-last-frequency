{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 1: Pseudo-Labeling Generator (ResNet-18 Only)\n",
                "\n",
                "Этот блокнот использует только ResNet-18 (5 фолдов) для генерации меток для уверенных сэмплов из теста.\n",
                "Настроен на 1-канальный вход для совместимости с твоими текущими весами."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, json, numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F, torchaudio, torchvision.models as models\n",
                "from tqdm.auto import tqdm\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "MODEL_PATH = '/kaggle/input/the-last-frequency-models'\n",
                "DATA_DIR = '/kaggle/input/the-last-frequency'\n",
                "THRESHOLD = 0.98  # Порог уверенности\n",
                "\n",
                "class CFG:\n",
                "    sample_rate, n_fft, hop_length, n_mels, target_frames = 16000, 1024, 256, 128, 64\n",
                "    batch_size, num_classes = 128, 35\n",
                "\n",
                "class SpecTransform(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.mel_spec = torchaudio.transforms.MelSpectrogram(sample_rate=CFG.sample_rate, n_fft=CFG.n_fft, hop_length=CFG.hop_length, n_mels=CFG.n_mels)\n",
                "        self.amp_to_db = torchaudio.transforms.AmplitudeToDB()\n",
                "    def forward(self, x):\n",
                "        x = self.amp_to_db(self.mel_spec(x))\n",
                "        if x.shape[-1] > CFG.target_frames: x = x[..., :CFG.target_frames]\n",
                "        elif x.shape[-1] < CFG.target_frames: x = F.pad(x, (0, CFG.target_frames - x.shape[-1]))\n",
                "        return x.unsqueeze(1)\n",
                "\n",
                "class AudioResNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        model = models.resnet18(weights=None)\n",
                "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
                "        model.fc = nn.Sequential(\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(model.fc.in_features, CFG.num_classes)\n",
                "        )\n",
                "        self.backbone, self.spec_layer = model, SpecTransform()\n",
                "    def forward(self, x): return self.backbone(self.spec_layer(x))\n",
                "\n",
                "class TestDataset(Dataset):\n",
                "    def __init__(self, waveforms): self.waveforms = waveforms\n",
                "    def __len__(self): return len(self.waveforms)\n",
                "    def __getitem__(self, idx): return torch.from_numpy(self.waveforms[idx]).float()\n",
                "\n",
                "def get_resnet_probs(waveforms):\n",
                "    loader = DataLoader(TestDataset(waveforms), batch_size=CFG.batch_size, shuffle=False)\n",
                "    all_probs = []\n",
                "    prefix = 'best_model_fold'\n",
                "    for fold in range(5):\n",
                "        path = f'{MODEL_PATH}/{prefix}_{fold}.pth'\n",
                "        if not os.path.exists(path): continue\n",
                "        print(f\"Loading ResNet-18 Fold {fold}...\")\n",
                "        m = AudioResNet().to(device)\n",
                "        m.load_state_dict(torch.load(path, map_location=device))\n",
                "        m.eval()\n",
                "        probs = []\n",
                "        with torch.no_grad():\n",
                "            for x in tqdm(loader, leave=False): \n",
                "                probs.append(F.softmax(m(x.to(device)), dim=1).cpu().numpy())\n",
                "        all_probs.append(np.concatenate(probs))\n",
                "    return np.mean(all_probs, axis=0)\n",
                "\n",
                "print(\"Predicting probabilities for test set (ResNet-18 Only)... \")\n",
                "pub, priv = np.load(f'{DATA_DIR}/public_test_waveforms.npy'), np.load(f'{DATA_DIR}/private_test_waveforms.npy')\n",
                "test_waveforms = np.concatenate([pub, priv])\n",
                "test_probs = get_resnet_probs(test_waveforms)\n",
                "\n",
                "confidences = np.max(test_probs, axis=1)\n",
                "pseudo_labels = np.argmax(test_probs, axis=1)\n",
                "mask = confidences > THRESHOLD\n",
                "\n",
                "print(f\"Found {np.sum(mask)} high-confidence samples out of {len(test_waveforms)}\")\n",
                "\n",
                "train_wavs = np.load(f'{DATA_DIR}/train_waveforms.npy')\n",
                "train_labels = np.load(f'{DATA_DIR}/train_labels.npy')\n",
                "\n",
                "expanded_wavs = np.concatenate([train_wavs, test_waveforms[mask]])\n",
                "expanded_labels = np.concatenate([train_labels, pseudo_labels[mask]])\n",
                "\n",
                "np.save('expanded_train_waveforms.npy', expanded_wavs)\n",
                "np.save('expanded_train_labels.npy', expanded_labels)\n",
                "print(\"Expanded dataset saved as expanded_train_waveforms.npy and expanded_train_labels.npy\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}